library("R.matlab", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
library("dtwclust", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
library(pacman) # needs to be installed first
# p_load is equivalent to combining both install.packages() and library()
p_load(R.matlab, plotly, extrafont, grDevices, ggpubr,
dplyr, stringr, tidyverse, utils, reshape2,
anomalize, MVN, fractal,
ecp, dfphase1,
MALDIquant, dtwclust,
knitr, kableExtra, dplyr, data.table,
RColorBrewer)
#forecast, TSclust,
load(file = "./data/RGenerated/NormMedianFilteredData.RData")
pen <- function(x) -length(x) #Equally penalizes every additional changepoint
len=nrow(subject1_medianf_norm)
changepoints_medianf <- list()
for (i in 1:15) {
df <- get(paste0("subject",i,"_medianf_norm"))
# Making the DF divisiable by the window size
# (i.e., we are removing the remainder so that our chunks are equally sized)
rows.to.keep <- nrow(df[,2:4]) %/% window.size
remainder <- nrow(df[,2:4]) %% window.size
df.MultivariateChangepoint<- df[1:(nrow(df)-remainder),
2:4] %>% as.matrix()
# Utilizing the e.agglo() from the ecp package
mem <- rep(1:rows.to.keep, each=window.size)
y = e.agglo(X=df.MultivariateChangepoint,
member= mem,
alpha = 1,
penalty = function(cp,Xts) mean(diff(sort(cp))))
fatigue_from_ECP <- subset(y$estimates,
((y$estimates>window.size) & (y$estimates<len-window.size))
) # Returns observation number
changepoints_medianf[[i]] <- df[fatigue_from_ECP,1]
cat('###',paste0("P", i), "{-}",'\n')
df_transformed <- melt(get(paste0("subject",i,"_medianf_norm")),
id.vars = "percent.time.from.start",
measure.vars=c("scaled.stride.len",
"scaled.stride.height",
"stride.duration"
)
) # ggplot data needs to be tall
df_transformed <- data.table(df_transformed)
df_transformed[variable == "scaled.stride.len", y_min := 0.4]
df_transformed[variable == "scaled.stride.len", y_max := 2.0]
df_transformed[variable == "scaled.stride.height", y_min := 0.04]
df_transformed[variable == "scaled.stride.height", y_max := 0.2]
df_transformed[variable == "stride.duration", y_min := 0.7]
df_transformed[variable == "stride.duration", y_max := 1.2]
assign(paste0("g",i),
ggplot(data = df_transformed,
aes(x=percent.time.from.start, y=value, group=variable,
color=variable,shape=variable)) +
geom_line() + theme_bw() +
ggtitle(paste("Changepoints on Median Filtered Data for Participant",i)) +
theme(legend.position="none",
#axis.text.x=element_text(angle=90,hjust=1),
plot.title = element_text(hjust = 0.5)) +
facet_wrap(~variable,nrow=3, scales = "free_y") +
geom_blank(aes(y = y_min)) +
geom_blank(aes(y = y_max)) +
geom_vline(xintercept= changepoints_medianf[[i]])
)
print(get(paste0("g",i)))
cat('\n')
cat(paste0('<source> <p> Based on the <b>ecp package</b>, the number of changepoints for participant ', i,
' is equal to: ',
length(changepoints_medianf[[i]]),
'. These changepoints are located at the following percent time(s) from start: ',
paste(round(changepoints_medianf[[i]], digits = 2), collapse = ", "),
'. The results from the analysis above can be found at: <a href="https://github.com/AmirBGitHub/fatigue-changepoint/data/RGenerated/ECPChangePointsMFData.RData">ECPChangePointsMFData.RData</a>. </p> </source>')
)
cat('\n \n')
}
load(file = "./data/RGenerated/NormMedianFilteredData.RData")
multvar_subjects_scaled <- vector("list", 15)
for (i in 1:15) {
df <- get(paste0("subject",i,"_medianf_norm"))
multvar_subjects_scaled[[i]] <- data.matrix(df[2:4], rownames.force = NA)
}
names(multvar_subjects_scaled) <- c(paste0("P", seq(1,15,1)))
multvar_subjects_scaled[[3]] <- {} # Deleting Participant 3
mvc <- tsclust(multvar_subjects_scaled, type = "hierarchical", k = 2L, distance = "dtw", seed = 390)
cat(paste0('<source> <p> To understand how the underlying multivariate time series methods are similar, we applied a heirarchical clustering algorithm based on the distances obtained using the <i> Dynamic Time Warping Method </i>. The resulting dendogram is shown in the figure below. </p> </source>'))
# distances.matrix <- as.matrix(distances)
# heatmap(distances.matrix)
plot(mvc, hang=0.1, check = TRUE,
axes = TRUE, ann = TRUE, ylab="Height",
main = "Cluster Dendogram based on the DTWARP distances")
cat(paste0('Based on the above dendogram, one can see that the best choice for total number of clusters is equal to: 3 or 4. This number was then used to cut of the dendogram tree using the  cutree function in R. We show the resulting cluster membership in the table below. The associated cluster assignments for both thresholds are as follows: \n', 'When using k=4, the assignments are as follows: \n'))
clusterCut3 <- cutree(mvc, 3)
clusterCut4 <- cutree(mvc, 4)
save(clusterCut3, clusterCut4, mvc,
file = "./data/RGenerated/MFClusters.RData")
# Printing the table using kable
kable(t(clusterCut4), row.names = NA, caption = "Cluster Assignment for each Participant") %>% column_spec(1, bold = T, width = "5em") %>% kable_styling(bootstrap_options = "striped", full_width = F)
# a R file used to create a plot based on clusterCut4
# See the file on GitHub Repo for more information
# Not directly included in the RMD since it is long
source('clusters.R')
source('clusters.R')
load(file = "./data/RGenerated/NormCusumData.RData")
multvar_subjects_scaled <- vector("list", 15)
for (i in 1:15) {
df <- get(paste0("subject",i,"_cusum_norm"))
multvar_subjects_scaled[[i]] <- data.matrix(df[2:4], rownames.force = NA)
}
names(multvar_subjects_scaled) <- c(paste0("P", seq(1,15,1)))
multvar_subjects_scaled[[3]] <- {} # Deleting Participant 3
mvc <- tsclust(multvar_subjects_scaled, type = "hierarchical", distance = "dtw", seed = 390)
cat(paste0('<source> <p> To understand how the underlying multivariate time series methods are similar, we applied a heirarchical clustering algorithm based on the distances obtained using the <i> Dynamic Time Warping Method </i>. The resulting dendogram is shown in the figure below. </p> </source>'))
# distances.matrix <- as.matrix(distances)
# heatmap(distances.matrix)
plot(mvc, hang=0.1, check = TRUE,
axes = TRUE, ann = TRUE, ylab="Height",
main = "Cluster Dendogram based on the DTWARP distances")
cat(paste0('Based on the above dendogram, one can see that the best choice for total number of clusters is equal to: 3 or 4. This number was then used to cut of the dendogram tree using the  cutree function in R. We show the resulting cluster membership in the table below. The associated cluster assignments for both thresholds are as follows: \n', 'When using k=4, the assignments are as follows: \n'))
clusterCut3 <- cutree(mvc, 3)
clusterCut4 <- cutree(mvc, 4)
save(clusterCut3, clusterCut4, mvc,
file = "./data/RGenerated/CusumClusters.RData")
kable(t(clusterCut4), row.names = NA, caption = "Cluster Assignment for each Participant") %>% column_spec(1, bold = T, width = "5em") %>% kable_styling(bootstrap_options = "striped", full_width = F)
# a R file used to create a plot based on clusterCut4
# See the file on GitHub Repo for more information
# Not directly included in the RMD since it is long
source('clustersCUSUMs.R')
